{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now define a function to read the fvecs file format of Sift1M dataset\n",
    "def read_fvecs(fp):\n",
    "    a = np.fromfile(fp, dtype='int32')\n",
    "    d = a[0]\n",
    "    return a.reshape(-1, d + 1)[:, 1:].copy().view('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "# data we will search through\n",
    "\n",
    "base = read_fvecs('./siftsmall/siftsmall_base.fvecs')  # 1M samples\n",
    "# also get some query vectors to search with\n",
    "query = read_fvecs('./siftsmall/siftsmall_query.fvecs')\n",
    "# take just one query (there are many in sift_learn.fvecs)\n",
    "# xq = xq[0].reshape(1, xq.shape[1])\n",
    "\n",
    "groundtruth = read_fvecs('./siftsmall/siftsmall_groundtruth.ivecs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.0492e-42, 5.2577e-42, 1.2359e-42, ..., 4.8765e-43, 4.2642e-42,\n",
       "        5.1666e-42],\n",
       "       [3.8970e-42, 1.3416e-41, 3.4920e-42, ..., 5.3936e-42, 4.0708e-42,\n",
       "        5.7481e-42],\n",
       "       [3.7933e-42, 1.3926e-41, 3.7807e-42, ..., 1.7530e-42, 1.2001e-41,\n",
       "        1.1453e-41],\n",
       "       ...,\n",
       "       [1.2366e-41, 1.2725e-41, 8.6068e-42, ..., 1.1460e-41, 8.2494e-42,\n",
       "        6.3969e-42],\n",
       "       [7.6511e-42, 7.6217e-42, 8.1415e-42, ..., 7.2854e-42, 1.0486e-41,\n",
       "        7.3316e-42],\n",
       "       [1.1325e-41, 1.2306e-41, 6.6800e-42, ..., 1.5414e-44, 3.4780e-42,\n",
       "        5.0881e-42]], dtype=float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"\n",
    "    Node for a navigable small world graph.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    idx : int\n",
    "        For uniquely identifying a node.\n",
    "\n",
    "    value : 1d np.ndarray\n",
    "        To access the embedding associated with this node.\n",
    "\n",
    "    neighborhood : set\n",
    "        For storing adjacent nodes.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    https://book.pythontips.com/en/latest/__slots__magic.html\n",
    "    https://hynek.me/articles/hashes-and-equality/\n",
    "    \"\"\"\n",
    "    __slots__ = ['idx', 'value', 'neighborhood']\n",
    "\n",
    "    def __init__(self, idx, value):\n",
    "        self.idx = idx\n",
    "        self.value = value\n",
    "        self.neighborhood = set()\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.idx)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return (\n",
    "            self.__class__ == other.__class__ and\n",
    "            self.idx == other.idx\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import random\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "def greedy_search(\n",
    "    graph: List[Node],\n",
    "    query: np.ndarray,\n",
    "    k: int=5,\n",
    "    m: int=50) -> Tuple[List[Tuple[float, int]], float]:\n",
    "    \"\"\"\n",
    "    Performs knn search using the navigable small world graph.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    graph :\n",
    "        Navigable small world graph from build_nsw_graph.\n",
    "\n",
    "    query : 1d np.ndarray\n",
    "        Query embedding that we wish to find the nearest neighbors.\n",
    "\n",
    "    k : int\n",
    "        Number of nearest neighbors returned.\n",
    "\n",
    "    m : int\n",
    "        The recall set will be chosen from m different entry points.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The list of nearest neighbors (distance, index) tuple.\n",
    "    and the average number of hops that was made during the search.\n",
    "    \"\"\"\n",
    "    result_queue = []\n",
    "    visited_set = set()\n",
    "    \n",
    "    hops = 0\n",
    "    for _ in range(m):\n",
    "        # random entry point from all possible candidates\n",
    "        entry_node = random.randint(0, len(graph) - 1)\n",
    "        entry_dist = distance.cosine(query, graph[entry_node].value)\n",
    "        candidate_queue = []\n",
    "        heapq.heappush(candidate_queue, (entry_dist, entry_node))\n",
    "\n",
    "        temp_result_queue = []\n",
    "        while candidate_queue:\n",
    "            candidate_dist, candidate_idx = heapq.heappop(candidate_queue)\n",
    "\n",
    "            if len(result_queue) >= k:\n",
    "                # if candidate is further than the k-th element from the result,\n",
    "                # then we would break the repeat loop\n",
    "                current_k_dist, current_k_idx = heapq.nsmallest(k, result_queue)[-1]\n",
    "                if candidate_dist > current_k_dist:\n",
    "                    break\n",
    "\n",
    "            for friend_node in graph[candidate_idx].neighborhood:\n",
    "                if friend_node not in visited_set:\n",
    "                    visited_set.add(friend_node)\n",
    "\n",
    "                    friend_dist = distance.cosine(query, graph[friend_node].value)\n",
    "                    heapq.heappush(candidate_queue, (friend_dist, friend_node))\n",
    "                    heapq.heappush(temp_result_queue, (friend_dist, friend_node))\n",
    "                    hops += 1\n",
    "\n",
    "        result_queue = list(heapq.merge(result_queue, temp_result_queue))\n",
    "\n",
    "    return heapq.nsmallest(k, result_queue), hops / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(\n",
    "    graph: List[Node],\n",
    "    query: np.ndarray,\n",
    "    k: int = 5,\n",
    "    m: int = 50,\n",
    "    beam_width: int = 10) -> Tuple[List[Tuple[float, int]], float]:\n",
    "    \"\"\"\n",
    "    Performs knn search using beam search on the navigable small world graph.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    graph :\n",
    "        Navigable small world graph from build_nsw_graph.\n",
    "\n",
    "    query : 1d np.ndarray\n",
    "        Query embedding that we wish to find the nearest neighbors.\n",
    "\n",
    "    k : int\n",
    "        Number of nearest neighbors returned.\n",
    "\n",
    "    m : int\n",
    "        The recall set will be chosen from m different entry points.\n",
    "\n",
    "    beam_width : int\n",
    "        Number of nodes to consider at each level of the search.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The list of nearest neighbors (distance, index) tuple.\n",
    "    and the average number of hops that was made during the search.\n",
    "    \"\"\"\n",
    "    result_queue = []\n",
    "    visited_set = set()\n",
    "\n",
    "    hops = 0\n",
    "    for _ in range(m):\n",
    "        entry_node = random.randint(0, len(graph) - 1)\n",
    "        entry_dist = distance.cosine(query, graph[entry_node].value)\n",
    "        candidate_queue = []\n",
    "        heapq.heappush(candidate_queue, (entry_dist, entry_node))\n",
    "\n",
    "        while candidate_queue:\n",
    "            temp_result_queue = []\n",
    "            # Consider up to beam_width best candidates\n",
    "            for _ in range(min(beam_width, len(candidate_queue))):\n",
    "                candidate_dist, candidate_idx = heapq.heappop(candidate_queue)\n",
    "\n",
    "                if len(result_queue) >= k:\n",
    "                    current_k_dist, _ = heapq.nsmallest(k, result_queue)[-1]\n",
    "                    if candidate_dist > current_k_dist:\n",
    "                        break\n",
    "\n",
    "                for friend_node in graph[candidate_idx].neighborhood:\n",
    "                    if friend_node not in visited_set:\n",
    "                        visited_set.add(friend_node)\n",
    "                        friend_dist = distance.cosine(query, graph[friend_node].value)\n",
    "                        heapq.heappush(candidate_queue, (friend_dist, friend_node))\n",
    "                        heapq.heappush(temp_result_queue, (friend_dist, friend_node))\n",
    "                        hops += 1\n",
    "\n",
    "            result_queue = list(heapq.merge(result_queue, temp_result_queue))\n",
    "\n",
    "    return heapq.nsmallest(k, result_queue), hops / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_nsw_graph(index_factors: np.ndarray, k: int) -> List[Node]:\n",
    "    n_nodes = index_factors.shape[0]\n",
    "    tqdm_loader = tqdm(index_factors)\n",
    "    tqdm_loader.set_description(\"Building Graph\")\n",
    "    graph = []\n",
    "    for i, value in enumerate(tqdm_loader):\n",
    "        node = Node(i, value)\n",
    "        if i > k:\n",
    "            neighbors, hops = greedy_search(graph, node.value, k)\n",
    "            neighbors_indices = [node_idx for _, node_idx in neighbors]\n",
    "        else:\n",
    "            neighbors_indices = list(range(i))\n",
    "\n",
    "        # insert bi-directional connection\n",
    "        node.neighborhood.update(neighbors_indices)\n",
    "        for i in neighbors_indices:\n",
    "            graph[i].neighborhood.add(node.idx)\n",
    "        \n",
    "        graph.append(node)\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Graph: 100%|██████████| 10000/10000 [40:28<00:00,  4.12it/s]\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "# selected_rows = np.random.choice(xb.shape[0], round(0.001*xb.shape[0]), replace=False)\n",
    "# index_factors = xb[selected_rows]\n",
    "graph = build_nsw_graph(base, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"graph.pkl\", \"wb\") as f:\n",
    "    pickle.dump(graph, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('graph.pkl', 'rb') as f:\n",
    "    objects = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results1 = greedy_search(objects, query[0], k=5)\n",
    "results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0.14819204807281494, 2176),\n",
       "  (0.1492038369178772, 3752),\n",
       "  (0.15418195724487305, 882),\n",
       "  (0.15591514110565186, 4009),\n",
       "  (0.15687423944473267, 2837)],\n",
       " 200.0)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = greedy_search(graph, query[0], k=5)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groundtruth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.0492e-42, 5.2577e-42, 1.2359e-42, 5.6178e-42, 3.9755e-42,\n",
       "       2.6625e-43, 5.0657e-42, 1.1435e-42, 1.4644e-42, 2.6400e-42,\n",
       "       3.1389e-43, 4.2221e-42, 4.0918e-43, 1.7825e-42, 7.4367e-42,\n",
       "       6.9196e-42, 1.8147e-42, 6.8944e-43, 1.2907e-41, 5.0797e-42,\n",
       "       1.7572e-42, 1.8105e-42, 2.2771e-42, 4.9788e-42, 1.6199e-42,\n",
       "       2.0459e-43, 1.4994e-43, 7.3302e-42, 2.7956e-42, 1.3370e-41,\n",
       "       4.9648e-42, 1.3674e-41, 1.3741e-41, 1.4910e-42, 1.3594e-41,\n",
       "       5.6949e-42, 3.4416e-42, 3.8718e-42, 4.5360e-42, 1.8455e-42,\n",
       "       4.9466e-42, 8.9823e-43, 2.3962e-42, 1.2453e-41, 5.9737e-42,\n",
       "       2.4607e-42, 8.3798e-43, 5.1848e-43, 3.8900e-42, 1.6956e-43,\n",
       "       5.6865e-42, 1.0152e-41, 2.6555e-42, 1.7376e-43, 1.2235e-41,\n",
       "       9.7530e-43, 6.0536e-42, 6.3437e-42, 5.6753e-42, 3.7106e-42,\n",
       "       2.3570e-42, 3.0184e-42, 2.3668e-42, 3.4136e-42, 2.8096e-42,\n",
       "       4.4982e-42, 5.6080e-42, 3.8872e-42, 1.2948e-42, 9.2906e-42,\n",
       "       4.8331e-42, 1.3752e-41, 4.9256e-42, 7.5320e-42, 4.0217e-43,\n",
       "       1.4545e-42, 5.7397e-42, 5.7369e-42, 1.3200e-42, 6.0550e-42,\n",
       "       1.7236e-43, 5.3446e-42, 1.3593e-43, 6.0158e-42, 5.8855e-43,\n",
       "       1.3640e-41, 2.6849e-42, 3.9110e-42, 2.0879e-43, 8.6026e-42,\n",
       "       1.3419e-41, 9.5807e-42, 4.1366e-42, 4.3973e-42, 4.0498e-42,\n",
       "       4.2964e-42, 3.9965e-42, 4.8765e-43, 4.2642e-42, 5.1666e-42],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groundtruth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0.14819204807281494, 2176),\n",
       "  (0.15418195724487305, 882),\n",
       "  (0.15591514110565186, 4009),\n",
       "  (0.15687423944473267, 2837),\n",
       "  (0.16574138402938843, 190)],\n",
       " 4.24)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = beam_search(graph, query[0], k=5, beam_width = 10)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "0:00:00.108000\n",
      "\n",
      "2000\n",
      "0:00:00.214994\n",
      "\n",
      "4000\n",
      "0:00:00.432016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    def time(graph):\n",
    "        start = datetime.now()\n",
    "        for _ in range(100):\n",
    "            query_point = np.random.rand(10)\n",
    "            nearest_neighbor = graph.greedy_search(query_point)\n",
    "        end = datetime.now()\n",
    "        print(len(graph.nodes))\n",
    "        print(end - start)\n",
    "        print()\n",
    "\n",
    "    def add(graph, node_count):\n",
    "        for _ in range(node_count):\n",
    "            graph.add_node(np.random.rand(10))\n",
    "\n",
    "    nsw1 = NSWGraph()\n",
    "    nsw2 = NSWGraph()\n",
    "    nsw3 = NSWGraph()\n",
    "\n",
    "    add(nsw1, 1000)\n",
    "    add(nsw2, 2000)\n",
    "    add(nsw3, 4000)\n",
    "\n",
    "    time(nsw1)\n",
    "    time(nsw2)\n",
    "    time(nsw3)\n",
    "\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
